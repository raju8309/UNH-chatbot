{
  "per_question": [
    {
      "id": "academic-standards:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8035297393798828,
      "sbert_cosine_chunk": 0.9422661066055298,
      "bertscore_f1": 0.5402770638465881,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.9420250058174133,
      "sbert_cosine_chunk": 0.8965908288955688,
      "bertscore_f1": 0.7425453066825867,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "academic-standards:q0003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8885767459869385,
      "sbert_cosine_chunk": 0.8782340884208679,
      "bertscore_f1": 0.5817605257034302,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.6523748636245728,
      "sbert_cosine_chunk": 0.6644579768180847,
      "bertscore_f1": 0.2734999358654022,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 0.9197207891481876,
      "ndcg@5": 0.9197207891481876
    },
    {
      "id": "academic-standards:q0005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.1580861657857895,
      "sbert_cosine_chunk": 0.7819793224334717,
      "bertscore_f1": -0.022102994844317436,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0006",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.18017473816871643,
      "sbert_cosine_chunk": 0.9346755743026733,
      "bertscore_f1": -0.06414833664894104,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9674679834891693
    },
    {
      "id": "academic-standards:q0007",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.37495240569114685,
      "sbert_cosine_chunk": 0.6394522190093994,
      "bertscore_f1": 0.17333541810512543,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9674679834891693
    },
    {
      "id": "academic-standards:q0008",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.44007179141044617,
      "sbert_cosine_chunk": 0.7839789986610413,
      "bertscore_f1": 0.20002351701259613,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9828920819566879
    },
    {
      "id": "academic-standards:q0009",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.24034330248832703,
      "sbert_cosine_chunk": 0.0,
      "bertscore_f1": -0.06072302162647247,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "academic-standards:q0010",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.242172971367836,
      "sbert_cosine_chunk": 0.48463067412376404,
      "bertscore_f1": 0.12223182618618011,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 1.0000001192092896,
      "sbert_cosine_chunk": 0.8319010734558105,
      "bertscore_f1": 1.0,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6934264036172708,
      "ndcg@5": 0.6934264036172708
    },
    {
      "id": "degree-requirements:q0002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5789318084716797,
      "sbert_cosine_chunk": 0.7137655019760132,
      "bertscore_f1": 0.2807093858718872,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "degree-requirements:q0003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7451068162918091,
      "sbert_cosine_chunk": 0.6806654334068298,
      "bertscore_f1": 0.3656511902809143,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9469024295259745
    },
    {
      "id": "degree-requirements:q0006",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5998523235321045,
      "sbert_cosine_chunk": 0.6995282173156738,
      "bertscore_f1": 0.16636507213115692,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0007",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7701655626296997,
      "sbert_cosine_chunk": 0.8194805383682251,
      "bertscore_f1": 0.33580511808395386,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0008",
      "nugget_precision": 1.0,
      "nugget_recall": 0.2,
      "nugget_f1": 0.33333333333333337,
      "sbert_cosine": 0.7222694158554077,
      "sbert_cosine_chunk": 0.7593130469322205,
      "bertscore_f1": 0.4149116277694702,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0010",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6342545747756958,
      "sbert_cosine_chunk": 0.61850905418396,
      "bertscore_f1": 0.056829411536455154,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "grading:q0003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.9325648546218872,
      "sbert_cosine_chunk": 0.8535966873168945,
      "bertscore_f1": 0.5240097045898438,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.3630698323249817,
      "sbert_cosine_chunk": 0.7605801820755005,
      "bertscore_f1": 0.05263102054595947,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6829671859741211,
      "sbert_cosine_chunk": 0.8243927359580994,
      "bertscore_f1": 0.2577199339866638,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0006",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6908398866653442,
      "sbert_cosine_chunk": 0.7933068871498108,
      "bertscore_f1": 0.23241977393627167,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0008",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.7181927561759949,
      "sbert_cosine_chunk": 0.8165774941444397,
      "bertscore_f1": 0.49967190623283386,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8772153153380493
    },
    {
      "id": "grading:q0009",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5105689764022827,
      "sbert_cosine_chunk": 0.7705469131469727,
      "bertscore_f1": 0.09568993747234344,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0010",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.17328235507011414,
      "sbert_cosine_chunk": 0.812050461769104,
      "bertscore_f1": 0.023044878616929054,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.573013186454773,
      "sbert_cosine_chunk": 0.34453263878822327,
      "bertscore_f1": 0.4533063471317291,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.45576682686805725,
      "sbert_cosine_chunk": 0.8320620059967041,
      "bertscore_f1": 0.19214306771755219,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 0.9197207891481876,
      "ndcg@5": 0.9197207891481876
    },
    {
      "id": "graduation:q0003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.8446353673934937,
      "sbert_cosine_chunk": 0.8711831569671631,
      "bertscore_f1": 0.6976181268692017,
      "recall@1": 0.5,
      "recall@3": 0.5,
      "recall@5": 0.5,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0004",
      "nugget_precision": 1.0,
      "nugget_recall": 1.0,
      "nugget_f1": 1.0,
      "sbert_cosine": 0.7847284078598022,
      "sbert_cosine_chunk": 0.9401459693908691,
      "bertscore_f1": 0.1257524937391281,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7781633138656616,
      "sbert_cosine_chunk": 0.7754818201065063,
      "bertscore_f1": 0.5543943643569946,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0006",
      "nugget_precision": 1.0,
      "nugget_recall": 1.0,
      "nugget_f1": 1.0,
      "sbert_cosine": 0.9074373841285706,
      "sbert_cosine_chunk": 0.9074373841285706,
      "bertscore_f1": 0.7262443900108337,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0007",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7920125722885132,
      "sbert_cosine_chunk": 0.7920125722885132,
      "bertscore_f1": 0.7223137021064758,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0008",
      "nugget_precision": 1.0,
      "nugget_recall": 1.0,
      "nugget_f1": 1.0,
      "sbert_cosine": 0.7104880213737488,
      "sbert_cosine_chunk": 0.0,
      "bertscore_f1": 0.18124978244304657,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "graduation:q0009",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6144571304321289,
      "sbert_cosine_chunk": 0.5673111081123352,
      "bertscore_f1": 0.14922116696834564,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6309297535714575,
      "ndcg@5": 0.6240505200038379
    },
    {
      "id": "graduation:q0010",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.745792031288147,
      "sbert_cosine_chunk": 0.7240488529205322,
      "bertscore_f1": 0.3979905843734741,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6309297535714575,
      "ndcg@5": 0.6309297535714575
    },
    {
      "id": "grading:q0011",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.8810644745826721,
      "sbert_cosine_chunk": 1.0000001192092896,
      "bertscore_f1": 0.6273078322410583,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0011",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.8460665345191956,
      "sbert_cosine_chunk": 0.9950257539749146,
      "bertscore_f1": 0.42888695001602173,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0012",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6759711503982544,
      "sbert_cosine_chunk": 0.9899089336395264,
      "bertscore_f1": 0.09604839980602264,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0012",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6817747354507446,
      "sbert_cosine_chunk": 0.9721181392669678,
      "bertscore_f1": 0.43382522463798523,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6309297535714575,
      "ndcg@5": 0.6509209298071326
    },
    {
      "id": "degree-requirements:q0013",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5901984572410583,
      "sbert_cosine_chunk": 0.9716793298721313,
      "bertscore_f1": 0.21296937763690948,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0014",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.4873771369457245,
      "sbert_cosine_chunk": 0.49286937713623047,
      "bertscore_f1": 0.20193518698215485,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0016",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5443793535232544,
      "sbert_cosine_chunk": 0.9626845717430115,
      "bertscore_f1": 0.07808340340852737,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0017",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.7495200634002686,
      "sbert_cosine_chunk": 0.9930050373077393,
      "bertscore_f1": 0.12116139382123947,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0011",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.6678218245506287,
      "sbert_cosine_chunk": 0.9336454272270203,
      "bertscore_f1": 0.515754222869873,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0012",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.42793428897857666,
      "sbert_cosine_chunk": 0.0,
      "bertscore_f1": 0.017907077446579933,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "admissions:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6289034485816956,
      "sbert_cosine_chunk": 0.49704092741012573,
      "bertscore_f1": 0.30988091230392456,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.38685280723454163
    },
    {
      "id": "admissions:q0002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6481380462646484,
      "sbert_cosine_chunk": 0.0,
      "bertscore_f1": 0.07523585855960846,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "admissions:q0003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.501590371131897,
      "sbert_cosine_chunk": 0.7030870318412781,
      "bertscore_f1": 0.029972856864333153,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "admissions:q0004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8023730516433716,
      "sbert_cosine_chunk": 0.7419956922531128,
      "bertscore_f1": 0.15961720049381256,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5
    },
    {
      "id": "admissions:q0005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8707096576690674,
      "sbert_cosine_chunk": 0.9935178756713867,
      "bertscore_f1": 0.4190022945404053,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "campus-life:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.15530411899089813,
      "sbert_cosine_chunk": 0.6510169506072998,
      "bertscore_f1": 0.0057092164643108845,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-support-services:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.9430187940597534,
      "sbert_cosine_chunk": 0.994131326675415,
      "bertscore_f1": 0.7711912989616394,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9469024295259745
    },
    {
      "id": "registration:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.43889838457107544,
      "sbert_cosine_chunk": 0.5141994953155518,
      "bertscore_f1": 0.05511092394590378,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "registration:q0002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.587104320526123,
      "sbert_cosine_chunk": 0.6309378147125244,
      "bertscore_f1": 0.014433729462325573,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "registration:q0003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.7214366793632507,
      "sbert_cosine_chunk": 0.8634713888168335,
      "bertscore_f1": 0.21608814597129822,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6309297535714575,
      "ndcg@5": 0.6509209298071326
    },
    {
      "id": "registration:q0004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.37441179156303406,
      "sbert_cosine_chunk": 0.43488478660583496,
      "bertscore_f1": -0.05322468653321266,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "fees-financial-support:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7871960401535034,
      "sbert_cosine_chunk": 0.9900640249252319,
      "bertscore_f1": 0.2870507538318634,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6309297535714575,
      "ndcg@5": 0.6309297535714575
    },
    {
      "id": "fees-financial-support:q0002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.58918297290802,
      "sbert_cosine_chunk": 0.6432009935379028,
      "bertscore_f1": 0.11918651312589645,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6934264036172708,
      "ndcg@5": 0.6934264036172708
    },
    {
      "id": "registration:q0006",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8505009412765503,
      "sbert_cosine_chunk": 0.994696855545044,
      "bertscore_f1": 0.3722069263458252,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6309297535714575,
      "ndcg@5": 0.6509209298071326
    },
    {
      "id": "registration:q0007",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.47901803255081177,
      "sbert_cosine_chunk": 0.957543671131134,
      "bertscore_f1": 0.1909935176372528,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.656007707118988,
      "sbert_cosine_chunk": 0.5934701561927795,
      "bertscore_f1": 0.29938918352127075,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.6182885020492784
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7095991373062134,
      "sbert_cosine_chunk": 0.9305325746536255,
      "bertscore_f1": 0.10344714671373367,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6934264036172708,
      "ndcg@5": 0.6934264036172708
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5378418564796448,
      "sbert_cosine_chunk": 0.5731757879257202,
      "bertscore_f1": 0.2415267676115036,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.3896663188934326,
      "sbert_cosine_chunk": 0.5125718712806702,
      "bertscore_f1": 0.09128495305776596,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.5012658353418871
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5791276097297668,
      "sbert_cosine_chunk": 0.6417961120605469,
      "bertscore_f1": 0.16150061786174774,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req006",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.302745521068573,
      "sbert_cosine_chunk": 0.9999998211860657,
      "bertscore_f1": 0.15834228694438934,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6309297535714575,
      "ndcg@5": 0.6797310500037655
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req007",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6650452613830566,
      "sbert_cosine_chunk": 0.9913356900215149,
      "bertscore_f1": 0.09052600711584091,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6934264036172708,
      "ndcg@5": 0.6934264036172708
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req008",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.48839375376701355,
      "sbert_cosine_chunk": 0.7048424482345581,
      "bertscore_f1": 0.42861008644104004,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8772153153380493
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req009",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7150386571884155,
      "sbert_cosine_chunk": 0.5812684297561646,
      "bertscore_f1": 0.2851295471191406,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6309297535714575,
      "ndcg@5": 0.6309297535714575
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req010",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.473443865776062,
      "sbert_cosine_chunk": 0.6476893424987793,
      "bertscore_f1": 0.14783182740211487,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8503449055347546
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req011",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5159910321235657,
      "sbert_cosine_chunk": 0.554591953754425,
      "bertscore_f1": 0.13729383051395416,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.43067655807339306
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req012",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.40819746255874634,
      "sbert_cosine_chunk": 0.5276241302490234,
      "bertscore_f1": 0.136015385389328,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.43067655807339306
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req013",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.3559368848800659,
      "sbert_cosine_chunk": 0.5509676933288574,
      "bertscore_f1": 0.08010419458150864,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req014",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.4676342010498047,
      "sbert_cosine_chunk": 0.5732122659683228,
      "bertscore_f1": 0.32460564374923706,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req015",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5310131907463074,
      "sbert_cosine_chunk": 0.6641073226928711,
      "bertscore_f1": 0.0812230110168457,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.6182885020492784
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req016",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.14230966567993164,
      "sbert_cosine_chunk": 0.16646581888198853,
      "bertscore_f1": -0.05317241698503494,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req017",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.3573527932167053,
      "sbert_cosine_chunk": 0.5153969526290894,
      "bertscore_f1": 0.037793274968862534,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8772153153380493
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req018",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8574960231781006,
      "sbert_cosine_chunk": 1.0000001192092896,
      "bertscore_f1": 0.47458717226982117,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req019",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.2376711666584015,
      "sbert_cosine_chunk": 0.337793231010437,
      "bertscore_f1": 0.06915123015642166,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.38685280723454163
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req020",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.3561762571334839,
      "sbert_cosine_chunk": 0.5428653955459595,
      "bertscore_f1": 0.07313913851976395,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.43067655807339306
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req021",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6207889318466187,
      "sbert_cosine_chunk": 0.5694839954376221,
      "bertscore_f1": 0.10304206609725952,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:accel001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.44841793179512024,
      "sbert_cosine_chunk": 0.5186216831207275,
      "bertscore_f1": 0.12128712236881256,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5706417189553201
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:accel002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6340517401695251,
      "sbert_cosine_chunk": 0.5936470627784729,
      "bertscore_f1": 0.3622216284275055,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6934264036172708,
      "ndcg@5": 0.6934264036172708
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:accel003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5316199064254761,
      "sbert_cosine_chunk": 0.5277625918388367,
      "bertscore_f1": 0.2558545470237732,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6309297535714575,
      "ndcg@5": 0.6309297535714575
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:accel004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6072163581848145,
      "sbert_cosine_chunk": 0.6958491802215576,
      "bertscore_f1": 0.17763446271419525,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5706417189553201
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:slo001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 1.0,
      "sbert_cosine_chunk": 0.8184239268302917,
      "bertscore_f1": 1.0,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:slo002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5591568946838379,
      "sbert_cosine_chunk": 0.5713777542114258,
      "bertscore_f1": 0.05219557136297226,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 0.9197207891481876,
      "ndcg@5": 0.8854598815714874
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:slo003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6982823610305786,
      "sbert_cosine_chunk": 1.0,
      "bertscore_f1": 0.3484896421432495,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8529278650606567
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:slo004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.9105364680290222,
      "sbert_cosine_chunk": 0.9317158460617065,
      "bertscore_f1": 0.6546100974082947,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8503449055347546
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:slo005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.4916800856590271,
      "sbert_cosine_chunk": 0.8649510741233826,
      "bertscore_f1": 0.17543990910053253,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:slo006",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.31095224618911743,
      "sbert_cosine_chunk": 0.3497866094112396,
      "bertscore_f1": 0.007051938213407993,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:slo007",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.26950544118881226,
      "sbert_cosine_chunk": 0.44843924045562744,
      "bertscore_f1": 0.09130649268627167,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8772153153380493
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:slo008",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8823119401931763,
      "sbert_cosine_chunk": 0.9009819030761719,
      "bertscore_f1": 0.7894614338874817,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6934264036172708,
      "ndcg@5": 0.6934264036172708
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:slo009",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.039035771042108536,
      "sbert_cosine_chunk": 0.19457998871803284,
      "bertscore_f1": -0.020083967596292496,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5706417189553201
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:slo010",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5461210608482361,
      "sbert_cosine_chunk": 0.4794023036956787,
      "bertscore_f1": 0.08908475190401077,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:slo011",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5394731163978577,
      "sbert_cosine_chunk": 0.6589539051055908,
      "bertscore_f1": 0.04141000658273697,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6309297535714575,
      "ndcg@5": 0.6240505200038379
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:slo012",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5303627848625183,
      "sbert_cosine_chunk": 0.7375903129577637,
      "bertscore_f1": 0.24339745938777924,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.38685280723454163
    },
    {
      "id": "cybersecurity-engineering-ms:desc001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6196985244750977,
      "sbert_cosine_chunk": 0.756827712059021,
      "bertscore_f1": 0.4280891716480255,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8772153153380493
    },
    {
      "id": "cybersecurity-engineering-ms:desc002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6190011501312256,
      "sbert_cosine_chunk": 0.6355919241905212,
      "bertscore_f1": 0.26348283886909485,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5706417189553201
    },
    {
      "id": "cybersecurity-engineering-ms:desc003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.19218680262565613,
      "sbert_cosine_chunk": 0.4283440113067627,
      "bertscore_f1": 0.21849425137043,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.38685280723454163
    },
    {
      "id": "cybersecurity-engineering-ms:desc004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.607237696647644,
      "sbert_cosine_chunk": 0.676106333732605,
      "bertscore_f1": 0.4019445776939392,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.6182885020492784
    },
    {
      "id": "cybersecurity-engineering-ms:desc005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5974076986312866,
      "sbert_cosine_chunk": 0.5238560438156128,
      "bertscore_f1": 0.2198263704776764,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5
    },
    {
      "id": "cybersecurity-engineering-ms:desc006",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5514079332351685,
      "sbert_cosine_chunk": 0.7181631326675415,
      "bertscore_f1": 0.2456502765417099,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.6182885020492784
    },
    {
      "id": "cybersecurity-engineering-ms:desc007",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.35674864053726196,
      "sbert_cosine_chunk": 0.32559138536453247,
      "bertscore_f1": 0.33808794617652893,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8529278650606567
    },
    {
      "id": "cybersecurity-engineering-ms:desc008",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7366582751274109,
      "sbert_cosine_chunk": 0.9937127828598022,
      "bertscore_f1": 0.26533058285713196,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "cybersecurity-engineering-ms:desc009",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8151317834854126,
      "sbert_cosine_chunk": 0.7589187622070312,
      "bertscore_f1": 0.6535954475402832,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "cybersecurity-engineering-ms:desc010",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6727686524391174,
      "sbert_cosine_chunk": 0.8658626079559326,
      "bertscore_f1": 0.23783233761787415,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.6182885020492784
    },
    {
      "id": "cybersecurity-engineering-ms:desc011",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6580694913864136,
      "sbert_cosine_chunk": 0.6516894102096558,
      "bertscore_f1": 0.5539867877960205,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.6182885020492784
    },
    {
      "id": "cybersecurity-engineering-ms:desc012",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5253021121025085,
      "sbert_cosine_chunk": 0.22275465726852417,
      "bertscore_f1": 0.233194962143898,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5
    },
    {
      "id": "cybersecurity-engineering-ms:desc013",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7907221913337708,
      "sbert_cosine_chunk": 0.7963039875030518,
      "bertscore_f1": 0.7471742033958435,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8503449055347546
    },
    {
      "id": "cybersecurity-engineering-ms:desc014",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5125221014022827,
      "sbert_cosine_chunk": 0.511572003364563,
      "bertscore_f1": 0.08125338703393936,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5437713091520254
    },
    {
      "id": "cybersecurity-engineering-ms:desc015",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.9006359577178955,
      "sbert_cosine_chunk": 0.9937127828598022,
      "bertscore_f1": 0.7446010112762451,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8529278650606567
    },
    {
      "id": "cybersecurity-engineering-ms:desc016",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6090918779373169,
      "sbert_cosine_chunk": 0.6453251838684082,
      "bertscore_f1": 0.24242591857910156,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5706417189553201
    },
    {
      "id": "cybersecurity-engineering-ms:req001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5966047644615173,
      "sbert_cosine_chunk": 0.5489604473114014,
      "bertscore_f1": 0.2004646211862564,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "cybersecurity-engineering-ms:req002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.2430490255355835,
      "sbert_cosine_chunk": 0.32198387384414673,
      "bertscore_f1": 0.15089410543441772,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8772153153380493
    },
    {
      "id": "cybersecurity-engineering-ms:req003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7051634788513184,
      "sbert_cosine_chunk": 0.7623814940452576,
      "bertscore_f1": 0.2386043518781662,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "information-technology-ms:desc001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7129201292991638,
      "sbert_cosine_chunk": 0.6781634092330933,
      "bertscore_f1": 0.7871379852294922,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "information-technology-ms:desc002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.2459384799003601,
      "sbert_cosine_chunk": 0.26625746488571167,
      "bertscore_f1": 0.09633658081293106,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5706417189553201
    },
    {
      "id": "information-technology-ms:desc003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.9827660918235779,
      "sbert_cosine_chunk": 0.7296319007873535,
      "bertscore_f1": 0.8649561405181885,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6309297535714575,
      "ndcg@5": 0.6309297535714575
    },
    {
      "id": "information-technology-ms:desc004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8023375868797302,
      "sbert_cosine_chunk": 0.6157768964767456,
      "bertscore_f1": 0.6827129125595093,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8772153153380493
    },
    {
      "id": "information-technology-ms:desc005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5725972652435303,
      "sbert_cosine_chunk": 0.6234006881713867,
      "bertscore_f1": 0.3085787892341614,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.43067655807339306
    },
    {
      "id": "information-technology-ms:desc006",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.663811445236206,
      "sbert_cosine_chunk": 0.9087821245193481,
      "bertscore_f1": 0.7125335931777954,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "information-technology-ms:desc007",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.4535520672798157,
      "sbert_cosine_chunk": 0.26708856225013733,
      "bertscore_f1": 0.0487963892519474,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "information-technology-ms:desc008",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.45303964614868164,
      "sbert_cosine_chunk": 0.49489617347717285,
      "bertscore_f1": 0.29496264457702637,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6309297535714575,
      "ndcg@5": 0.6309297535714575
    },
    {
      "id": "information-technology-ms:desc009",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.2884232997894287,
      "sbert_cosine_chunk": 0.3969179093837738,
      "bertscore_f1": 0.15407007932662964,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 0.9197207891481876,
      "ndcg@5": 0.9197207891481876
    },
    {
      "id": "information-technology-ms:req001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6636499166488647,
      "sbert_cosine_chunk": 0.6178184747695923,
      "bertscore_f1": 0.14413952827453613,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "information-technology-ms:req002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6084555983543396,
      "sbert_cosine_chunk": 0.6572709679603577,
      "bertscore_f1": 0.16549381613731384,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "information-technology-ms:req003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6020007133483887,
      "sbert_cosine_chunk": 0.6203470230102539,
      "bertscore_f1": 0.30743667483329773,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "information-technology-ms:req004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5677943825721741,
      "sbert_cosine_chunk": 0.8641399145126343,
      "bertscore_f1": 0.0500653013586998,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6934264036172708,
      "ndcg@5": 0.6934264036172708
    },
    {
      "id": "information-technology-ms:req005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7344462275505066,
      "sbert_cosine_chunk": 0.6812337636947632,
      "bertscore_f1": 0.23698580265045166,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "information-technology-ms:req006",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5266560912132263,
      "sbert_cosine_chunk": 0.8170043230056763,
      "bertscore_f1": 0.15202809870243073,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6309297535714575,
      "ndcg@5": 0.6309297535714575
    },
    {
      "id": "information-technology-ms:req007",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6705849170684814,
      "sbert_cosine_chunk": 0.7090095281600952,
      "bertscore_f1": 0.101471908390522,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "information-technology-ms:req008",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.20929093658924103,
      "sbert_cosine_chunk": 0.42107856273651123,
      "bertscore_f1": 0.09148872643709183,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.38685280723454163
    },
    {
      "id": "information-technology-ms:req009",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.41818296909332275,
      "sbert_cosine_chunk": 0.4426088035106659,
      "bertscore_f1": 0.02816537395119667,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "information-technology-ms:req010",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.4213480055332184,
      "sbert_cosine_chunk": 0.7449589967727661,
      "bertscore_f1": 0.38353708386421204,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8503449055347546
    },
    {
      "id": "information-technology-ms:req011",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6998755931854248,
      "sbert_cosine_chunk": 0.7593379616737366,
      "bertscore_f1": 0.4816959798336029,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "information-technology-ms:req012",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6578197479248047,
      "sbert_cosine_chunk": 0.711862325668335,
      "bertscore_f1": 0.302146315574646,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "information-technology-ms:req013",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.40640321373939514,
      "sbert_cosine_chunk": 0.4747849106788635,
      "bertscore_f1": -0.00804856140166521,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.38685280723454163
    },
    {
      "id": "information-technology-ms:req014",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.3596627116203308,
      "sbert_cosine_chunk": 0.41428080201148987,
      "bertscore_f1": 0.10503072291612625,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "information-technology-ms:req015",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6697344183921814,
      "sbert_cosine_chunk": 0.6378830671310425,
      "bertscore_f1": 0.3393568694591522,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "information-technology-ms:req016",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.26066166162490845,
      "sbert_cosine_chunk": 0.3798096477985382,
      "bertscore_f1": 0.28055891394615173,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "information-technology-ms:req017",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.506974995136261,
      "sbert_cosine_chunk": 0.7410104870796204,
      "bertscore_f1": 0.1735367327928543,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "information-technology-ms:req018",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.1263657808303833,
      "sbert_cosine_chunk": 0.28612086176872253,
      "bertscore_f1": -0.0867386981844902,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "information-technology-ms:req019",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5742518901824951,
      "sbert_cosine_chunk": 0.9971166849136353,
      "bertscore_f1": 0.07595737278461456,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5
    },
    {
      "id": "information-technology-ms:req020",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6159447431564331,
      "sbert_cosine_chunk": 0.799338698387146,
      "bertscore_f1": 0.13656172156333923,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "information-technology-ms:req021",
      "nugget_precision": 1.0,
      "nugget_recall": 1.0,
      "nugget_f1": 1.0,
      "sbert_cosine": 0.735984206199646,
      "sbert_cosine_chunk": 0.6858350038528442,
      "bertscore_f1": 0.4601672291755676,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "accelerated-masters:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6716166734695435,
      "sbert_cosine_chunk": 0.8102518320083618,
      "bertscore_f1": 0.25486746430397034,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "accelerated-masters:q0002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7244500517845154,
      "sbert_cosine_chunk": 0.7889570593833923,
      "bertscore_f1": 0.3376465141773224,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "accelerated-masters:q0003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6544414758682251,
      "sbert_cosine_chunk": 0.6677120327949524,
      "bertscore_f1": 0.12025482952594757,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "accelerated-masters:q0004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.3714514970779419,
      "sbert_cosine_chunk": 0.5661079287528992,
      "bertscore_f1": 0.15058013796806335,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "accelerated-masters:q0005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6217596530914307,
      "sbert_cosine_chunk": 0.7811564207077026,
      "bertscore_f1": 0.4103710353374481,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "accelerated-masters:q0006",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6770191192626953,
      "sbert_cosine_chunk": 0.6920532584190369,
      "bertscore_f1": 0.23705890774726868,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "grading:q0013",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.26752719283103943,
      "sbert_cosine_chunk": 0.6877361536026001,
      "bertscore_f1": 0.05962398275732994,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0014",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5590256452560425,
      "sbert_cosine_chunk": 0.8380942344665527,
      "bertscore_f1": 0.2853008210659027,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "registration:q0008",
      "nugget_precision": 1.0,
      "nugget_recall": 1.0,
      "nugget_f1": 1.0,
      "sbert_cosine": 0.7848551273345947,
      "sbert_cosine_chunk": 0.7292954921722412,
      "bertscore_f1": 0.6007733345031738,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8772153153380493
    },
    {
      "id": "registration:q0009",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.45876389741897583,
      "sbert_cosine_chunk": 0.6537041664123535,
      "bertscore_f1": 0.27822983264923096,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0019",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5204843282699585,
      "sbert_cosine_chunk": 0.9198319315910339,
      "bertscore_f1": 0.11896013468503952,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9469024295259745
    },
    {
      "id": "admissions:q0174",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5741642713546753,
      "sbert_cosine_chunk": 0.0,
      "bertscore_f1": -0.023915421217679977,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "admissions:q0175",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8333679437637329,
      "sbert_cosine_chunk": 0.8185189962387085,
      "bertscore_f1": 0.36625510454177856,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "admissions:q0177",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8506848812103271,
      "sbert_cosine_chunk": 0.9064562916755676,
      "bertscore_f1": 0.445418119430542,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0178",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6739784479141235,
      "sbert_cosine_chunk": 0.8062158823013306,
      "bertscore_f1": 0.33127933740615845,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0179",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.009360842406749725,
      "sbert_cosine_chunk": 0.0,
      "bertscore_f1": 0.028481805697083473,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "campus-life:q0180",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7490745782852173,
      "sbert_cosine_chunk": 0.7159311771392822,
      "bertscore_f1": 0.3506622910499573,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0181",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.9060643911361694,
      "sbert_cosine_chunk": 0.9424630999565125,
      "bertscore_f1": 0.5255233645439148,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "fees-financial-support:q0182",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.8302087783813477,
      "sbert_cosine_chunk": 1.0,
      "bertscore_f1": 0.5978823900222778,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8772153153380493
    },
    {
      "id": "fees-financial-support:q0183",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.25775671005249023,
      "sbert_cosine_chunk": 0.5901793837547302,
      "bertscore_f1": -0.14487162232398987,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9558295932317544
    },
    {
      "id": "fees-financial-support:q0184",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6996921300888062,
      "sbert_cosine_chunk": 0.7782753705978394,
      "bertscore_f1": 0.2312956601381302,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "registration:q0185",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8209292888641357,
      "sbert_cosine_chunk": 0.9536676406860352,
      "bertscore_f1": 0.3076814115047455,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 0.9197207891481876,
      "ndcg@5": 0.9060254355346823
    },
    {
      "id": "courses:q0186",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6290290951728821,
      "sbert_cosine_chunk": 0.893460750579834,
      "bertscore_f1": 0.29237961769104004,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6934264036172708,
      "ndcg@5": 0.6934264036172708
    },
    {
      "id": "degree-requirements:q0187",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.842793881893158,
      "sbert_cosine_chunk": 0.9032008647918701,
      "bertscore_f1": 0.5603917837142944,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0188",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.9530688524246216,
      "sbert_cosine_chunk": 0.9440087080001831,
      "bertscore_f1": 0.5135631561279297,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 0.9197207891481876,
      "ndcg@5": 0.9060254355346823
    },
    {
      "id": "graduation:q0189",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7994612455368042,
      "sbert_cosine_chunk": 0.8544874787330627,
      "bertscore_f1": 0.6744012832641602,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0190",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5708221197128296,
      "sbert_cosine_chunk": 0.9465284943580627,
      "bertscore_f1": 0.1947070211172104,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "credit-transfer:q0191",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7333844900131226,
      "sbert_cosine_chunk": 0.9806249141693115,
      "bertscore_f1": 0.2892548441886902,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9674679834891693
    },
    {
      "id": "registration:q0192",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7258726954460144,
      "sbert_cosine_chunk": 0.8121496438980103,
      "bertscore_f1": 0.15639106929302216,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8503449055347546
    },
    {
      "id": "degree-requirements:q0193",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6713103652000427,
      "sbert_cosine_chunk": 0.6963348388671875,
      "bertscore_f1": 0.11505240201950073,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0194",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7161493897438049,
      "sbert_cosine_chunk": 0.9311795234680176,
      "bertscore_f1": 0.26171526312828064,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0196",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.50885009765625,
      "sbert_cosine_chunk": 0.746559739112854,
      "bertscore_f1": 0.14862538874149323,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0197",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.8160254955291748,
      "sbert_cosine_chunk": 0.9548460841178894,
      "bertscore_f1": 0.4689185619354248,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 0.9197207891481876,
      "ndcg@5": 0.9197207891481876
    },
    {
      "id": "registration:q0198",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.38946017622947693,
      "sbert_cosine_chunk": 0.7054617404937744,
      "bertscore_f1": 0.12850716710090637,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0200",
      "nugget_precision": 1.0,
      "nugget_recall": 1.0,
      "nugget_f1": 1.0,
      "sbert_cosine": 0.7813591957092285,
      "sbert_cosine_chunk": 0.8536223769187927,
      "bertscore_f1": 0.3770734965801239,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "grading:q0201",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6273506879806519,
      "sbert_cosine_chunk": 1.0,
      "bertscore_f1": 0.1554509550333023,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0202",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.94511878490448,
      "sbert_cosine_chunk": 0.9285751581192017,
      "bertscore_f1": 0.46447721123695374,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "fees-financial-support:q0203",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.2525169551372528,
      "sbert_cosine_chunk": 0.8357797265052795,
      "bertscore_f1": -0.15293502807617188,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5
    },
    {
      "id": "registration:q0199",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.3919743001461029,
      "sbert_cosine_chunk": 0.21652063727378845,
      "bertscore_f1": 0.0648069828748703,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "registration:q0200",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6232785582542419,
      "sbert_cosine_chunk": 0.6963717937469482,
      "bertscore_f1": 0.04827653244137764,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9674679834891693
    },
    {
      "id": "registration:q0201",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7465593814849854,
      "sbert_cosine_chunk": 1.0000001192092896,
      "bertscore_f1": 0.531953752040863,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8529278650606567
    },
    {
      "id": "degree-requirements:q0203",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.3897632360458374,
      "sbert_cosine_chunk": 0.4727708399295807,
      "bertscore_f1": 0.07327298820018768,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0202",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8401790261268616,
      "sbert_cosine_chunk": 0.7735453844070435,
      "bertscore_f1": 0.5878472924232483,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    }
  ],
  "summary": {
    "count": 188,
    "nugget_precision": 1.0,
    "nugget_recall": 0.06843971631205674,
    "nugget_f1": 0.08333333333333331,
    "sbert_cosine": 0.59329176787287,
    "sbert_cosine_chunk": 0.6929827510042393,
    "bertscore_f1": 0.26978194234803554,
    "recall@1": 0.5079787234042553,
    "recall@3": 0.7473404255319149,
    "recall@5": 0.8058510638297872,
    "ndcg@1": 0.5106382978723404,
    "ndcg@3": 0.6446145933478958,
    "ndcg@5": 0.6603777902261119
  }
}