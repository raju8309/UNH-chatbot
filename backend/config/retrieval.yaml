policy_terms:
  - grade
  - grading
  - policy
  - policies
  - regulation
  - regulations
  - requirement
  - requirements
  - academic standards
  - degree requirements
  - gre
  - gmat
  - english proficiency
  - toefl
  - ielts
  - duolingo
  - transfer credit
  - add/drop
  - withdrawal
  - leave of absence
  - pass/fail
  - probation
  - dismissal

tier_boosts:
  0: 3.0
  1: 1.5
  2: 1.2
  3: 1.0
  4: 1.0

intent:
  course_keywords: ["course descriptions", "show courses", "list courses", "prerequisite", "prerequisites", "syllabus"]
  degree_keywords:
    - ms
    - m.s.
    - phd
    - ph.d
    - mba
    - mfa
    - ma
    - msc
    - program requirements
    - curriculum
    - concentration
    - how many credits
    - credit requirement
    - admissions
    - gre
    - gpa
  course_code_regex: "\\b[A-Z]{3,5}\\s?\\d{3}[A-Z]?\\b"

nudges:
  policy_acadreg_url: 1.07
  same_program_bonus: 2.00
  course_url_bonus: 1.80
  course_title_bonus: 1.40
  other_program_tier34_penalty: 0.25

guarantees:
  ensure_tier1_on_policy: true
  ensure_tier4_on_program: true

tier4_gate:
  use_embedding: true
  min_title_sim: 0.35
  min_alt_sim: 0.32

retrieval_sizes:
  topn_default: 120
  k: 5

chunking:
  enable_contextual_headers: true
  enable_overlap: true
  text_chunk_size: 2
  text_overlap: 1
  list_chunk_size: 5
  list_overlap: 2

followups:
  hints:
    - "for "
    - "now "
    - "do it for"
    - "for the"
    - "make that for"
    - "do that for"
    - "do it"
    - "that"
    - "this"
    - "same"

beam_search:
  enabled: false
  beam_width: 5
  num_candidates: 3
  diversity_penalty: 0.3

gold_set:
  enabled: true
  gold_file_path: "../automation_testing/gold.jsonl"

  # Direct answer logic
  enable_direct_answer: true
  direct_answer_threshold: 0.85

  # Boosting settings
  tier_boost: 3.0
  gold_chunk_boost: 2.5
  gold_url_boost: 1.5
  gold_answer_boost: 1.8
  ensure_gold_in_results: true
  min_gold_score: 0.3
  prefer_gold_on_uncertainty: true

enhancements:
  enabled: false
  query_enhancement:
    enabled: false
    expand_acronyms: true
    boost_key_terms: true
    policy_rewriting: true

  reranking:
    enabled: false
    use_cross_encoder: true
    use_tfidf: true
    use_metadata: true
    max_candidates_for_cross_encoder: 20
    diversity_threshold: 0.7
    weights:
      semantic: 0.25
      cross_encoder: 0.45
      tfidf: 0.15
      metadata: 0.15

  compression:
    enabled: false
    deduplicate: true
    aggressive: false
    min_chunk_length: 200
    compression_ratio:
      tier1: 0.8
      tier2: 0.7
      tier3: 0.6
      tier4: 0.5

performance:
  lazy_load_models: true
  cache_size: 128
  max_tokens: 200
  use_finetuned_model: false

  gold_chunk_boost: 2.5
  gold_url_boost: 1.5
  gold_answer_boost: 1.8

  ensure_gold_in_results: true
  min_gold_score: 0.3
  prefer_gold_on_uncertainty: true

  semantic_match:
    enabled: true
    threshold: 0.85

synthetic_qa:
  enabled: false
  boost_synthetic_qa: 1.3
  min_chunk_length: 50
  question_model: "google/flan-t5-large"
  temperature: 0.5
  max_question_length: 60
  force_cpu: true
  generate_for_tiers: [1, 2]

stats:
  total_entries: 0
  categories: {}
